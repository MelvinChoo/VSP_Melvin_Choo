{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f34e69",
   "metadata": {},
   "source": [
    "# Lab Assignment 4 -- Data and Pandas\n",
    "In this lab, you will complete a series of exercises related to the lecture material on data and Pandas using some real datasets. Each exercise will focus around a single dataset and contain multiple steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the libraries you will need\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a79149",
   "metadata": {},
   "source": [
    "## Exercise 1 -- Unemployment Data\n",
    "Below, we load in data on Unemployment in the United States at the State level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Not Edit\n",
    "url = \"https://datascience.quantecon.org/assets/data/state_unemployment.csv\"\n",
    "unemp = pd.read_csv(url, parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01d47d",
   "metadata": {},
   "source": [
    "## Exercise 1a -- Displaying Data\n",
    "Complete the following steps:\n",
    "- In two cells below, display the top 7 rows  and the bottom 3 rows of `unemp`. \n",
    "- In the third cell, change `unemp` so its column names are strictly lowercase\n",
    "- Display the resulting DataFrame by calling `unemp` at the bottomg of the third cell.\n",
    "\n",
    "From a \"tidy\" perspective, what is an observation in this data? Explain why. Answer in the Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1a -- Top 7\n",
    "print(unemp.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6da9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Exercise 1a -- Bottom 3\n",
    "print(unemp.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec83638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1a -- Rename Columns\n",
    "unemp.columns = unemp.columns.str.lower()\n",
    "unemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53957b16",
   "metadata": {},
   "source": [
    "### Response to Exercise 1a\n",
    "\n",
    "From a tidy perspective, the data is considered tidy because each column contains a single variable. Furthermore, each row represents a single observation (the state's labor force and unemployment rate on a specific date). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517e89e",
   "metadata": {},
   "source": [
    "## Exercise 1b -- Creating Variables & Index Setting\n",
    "Complete the following steps:\n",
    "- Create a column in `unemp` called \"year\" that is equal to the year of the date. \n",
    "- Change the index of `unemp` so that the index (or indices) reflect the observational units. \n",
    "- Display the indices.  \n",
    "\n",
    "In the Markdown cell below, address the following prompts:\n",
    "1. How many indices are there?\n",
    "2. Why are there this many indices? Write an equation that explains it.\n",
    "3. Is one of your indices a `DateTimeIndex` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf7d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1b Code\n",
    "unemp['year'] = unemp['date'].dt.year\n",
    "unemp\n",
    "unemp.set_index(['state', 'date'], inplace=True)\n",
    "print(unemp.head())  # To check the first few rows and the new index\n",
    "print(unemp.index)   # To verify the structure of the new MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0aa8fe",
   "metadata": {},
   "source": [
    "### Response to Exercise 1b\n",
    "\n",
    "#### How many indices are there?\n",
    "\n",
    "There are two indices: \"date\" and \"state\".\n",
    "\n",
    "#### Why are there this many indices? Write an equation that explains it.\n",
    "\n",
    "There are this many indices because we need both the date and the state to uniquely identify each observation in the dataset. The total number of indices is the product of the number of unique dates and the number of unique states. \n",
    "\n",
    "Denoting the number of unique dates as D and the number of unique states as S, the total number of unique index entries is:\n",
    "\n",
    "D * S = DS\n",
    "\n",
    "#### Is one of your indices a DateTimeIndex object?\n",
    "\n",
    "Yes, the \"date\" index is a DateTimeIndex object because it was parsed as dates when we read the CSV file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037848f",
   "metadata": {},
   "source": [
    "### Exercise 1c -- Plotting Annual Averages\n",
    "Complete the following steps:\n",
    "1. Using `tiny_unemp`, find the year-state average of the unemployment rate and save it to `yearly_state_unemp`.\n",
    "2. Reshape `yearly_state_unemp` by using `unstack()`. Ensure that your row indices are years and your column variables are states.  \n",
    "3. Display `yearly_state_unemp` by making it the last line in the cell.\n",
    "4. Note that the `unemploymentrate` level is not very useful because all of the numbers are unemployment rates. Let's remove it by using `.droplevel()` on `yearly_state_unemp`. Call this new DataFrame `clean_state_unemp` You may want to reference the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html) to see which argument you will need. \n",
    "5. Use the `.plot()` method on `clean_state_unemp`.\n",
    "6. In the next cell, use the `.plot()` method on `yearly_state_unemp`.\n",
    "\n",
    "In the Markdown cell below **answer the following questions**: \n",
    "1. What is the most salient real world phenomenon this is visible in the plot?\n",
    "2. Compare the two plots. How did removing the `unemploymentrate` level change the plot?\n",
    "\n",
    "**Hints**\n",
    "- You can use `df.drop()` ([documentation here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html))  to get rid of the `laborforce` column when creating `yearly_state_unemp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8819ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this code\n",
    "tiny_unemp = unemp.loc[[\"Colorado\", \"California\", \"Alabama\", \"New York\", \"Florida\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bec9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1c -- Steps 1-3\n",
    "# 1. Calculate the average unemployment rate by year and state\n",
    "yearly_state_unemp = tiny_unemp.groupby(['year', 'state'])['unemploymentrate'].mean()\n",
    "\n",
    "# 2. Reshape the DataFrame using unstack()\n",
    "clean_state_unemp = yearly_state_unemp.unstack()\n",
    "\n",
    "# 3. Display the reshaped DataFrame\n",
    "print(yearly_state_unemp)\n",
    "print(clean_state_unemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42aa27f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1c -- Steps 4 & 5\n",
    "\n",
    "# 4. Not done due to groupby function\n",
    "\n",
    "clean_state_unemp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1c -- Step 6\n",
    "yearly_state_unemp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5c33c",
   "metadata": {},
   "source": [
    "### Response to Exercise 1c\n",
    "\n",
    "The most salient real world phenomenon that is visible in the plot is the cyclical pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96daf06e",
   "metadata": {},
   "source": [
    "## Exercise 1d -- Using Lags to Plot Difference\n",
    "Instead of plotting the unemployment rate average over time, we will plot the annual difference between unemployment rates over time for each state. To do this, complete the following steps:\n",
    "1. Create a DataFrame called `shifted_unemp` and assign it to `clean_state_unemp` shifted by 1.\n",
    "2. Create a DataFrame called `change_unemp` and assign it to the the difference between `clean_state_unemp` and `shifted_unemp` divided by `shifted_unemp`.\n",
    "3. Call `.plot()` on `change_unemp`.\n",
    "\n",
    "Answer the following questions in the markdown cell below. \n",
    "1. Why is the year 2000 no longer being plotted? Look at the `change_unemp` DataFrame if you are unsure.\n",
    "2. Which state saw the largest annual increase in unemployment during this period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee44c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1d code\n",
    "shifted_unemp = clean_state_unemp.shift(1)\n",
    "change_unemp = (clean_state_unemp - shifted_unemp) / shifted_unemp\n",
    "change_unemp.plot()\n",
    "change_unemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6be3a0",
   "metadata": {},
   "source": [
    "### Response to Exercise 1d\n",
    "\n",
    "1. Year 2000 is no longer plotted due to the shift by 1 period. This is so that the annual difference between unemployment rates can be calculated by assigning values in Year 2000 as zero.\n",
    "\n",
    "2. Alabama saw the largest annual increase in unemployemnt as shown by the highest spike in blue.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3f612",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In this question, we're going to look at data on daily Covid cases in British Columbia from the [COVID-19 Canada Open Data Working Group](https://github.com/ccodwg/Covid19Canada). This data is broken down into five health regions:\n",
    "- Fraser Health (Fraser)\n",
    "- Interior Health (Interior)\n",
    "- Northern Health (Northern)\n",
    "- Vancouver Coastal Health (Vancouver Coastal)\n",
    "- Vancouver Island Health Authority (Island)\n",
    "\n",
    "You can see the geography of these regions below (Image from gov.bc.ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47643b",
   "metadata": {},
   "source": [
    "<img src = \"https://www2.gov.bc.ca/assets/gov/health/managing-your-health/mental-health-substance-use/find-services-map-large.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531aed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dowlonad the Data -- don't edit this cell\n",
    "cases_bc = pd.read_csv(r\"C:\\Users\\melvj\\Downloads\\covid_cases_bc.csv\")\n",
    "cases_bc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd4dea",
   "metadata": {},
   "source": [
    "## Exercise 2a -- Checking the Data\n",
    "`cases_bc` contains daily reported covid cases per hundred thousand people in BC for the year 2021. The data is broken down by health region. Before working with the data, you should learn how its structured and check it for potential errors. Answer the following questions in the first markdown cell below.\n",
    "1. What is an observation (or row) in the dataset?\n",
    "2. What is the index? Could we turn one of our variables into an index? Which one?\n",
    "3. Does it make sense for any of the values in the table to be negative? Why or why not?\n",
    "\n",
    "Now complete the following steps:\n",
    "- Make it so the date is our index and check whether it is a `DateTimeIndex`. Afterwards, display `cases_bc` by making it the last line of the cell below. \n",
    "- In the second cell, call `.dropna()` on cases_bc. \n",
    "- In the third cell, us `.any()` and comparison operators **applied to `cases_bc`** to display all dates on which at least one of the health regions has a negative value. Call this DataFrame `neg_values`. Display `neg_values` by making it the last line of the cell. (**Hint**: Observe what happens when you use a comparison operator on a DataFrame. You can use the output to easily form an index for your DataFrame.)\n",
    "- If any dates had a negative values, use comparison operators to set all negative values in `cases_bc` to `NaN`.\n",
    "\n",
    "\n",
    "Answer the following Questions in the second Markdown cell.\n",
    "\n",
    "4. Did dropping missing value change the DataFrame at all?\n",
    "5. Did you find any negative values? If so, they have been turned into `NaN` values and will not be used in future analysis. What would be a possible alternative to this approach?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4d351",
   "metadata": {},
   "source": [
    "### Response to Exercise 2a Questions 1-3\n",
    "\n",
    "1. An observation or row in the dataset shows the daily reported covid cases per hundred thousand people in the different health regions in BC for the year 2021.\n",
    "\n",
    "2. Currently, the index is the first column, which appears to be the default integer-based index that pandas assigns when creating a DataFrame. We could turn the date_report variable into an index as it allows us to uniquely identify each row of the dataframe. \n",
    "\n",
    "3. No, it does not make sense for the values to be neagtive as the number of cases per health region must be a positve integer. The minimum value would be zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2a -- Step 1\n",
    "cases_bc.set_index('date_report', inplace=True)\n",
    "is_datetime_index = isinstance(cases_bc.index, pd.DatetimeIndex)\n",
    "print(f\"Is the index a DateTimeIndex? {is_datetime_index}\")\n",
    "cases_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8472f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2a -- Step 2\n",
    "cases_bc = cases_bc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af050da4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 2a -- Step 3\n",
    "neg_values = cases_bc[(cases_bc < 0).any(axis=1)]\n",
    "\n",
    "# Display neg_values DataFrame\n",
    "print(\"Dates with negative values:\")\n",
    "neg_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a8a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2a -- Step 4\n",
    "\n",
    "cases_bc[cases_bc < 0] = float('NaN')\n",
    "cases_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d5242",
   "metadata": {},
   "source": [
    "### Response to Exercise 2a 4-5\n",
    "\n",
    "4. No, dropping missing values do not change the dataframe.\n",
    "\n",
    "5. Yes, there were negative values. An alternative apporach would be to replace negative values with the minimum value of zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d78f12",
   "metadata": {},
   "source": [
    "## Exercise 2b -- Aggregations\n",
    "Using aggregators with the axis argument, complete the following steps:\n",
    "1. At each date, find the minimum number of cases per 100,000 across health regions. Print the top 3 rows of the resulting series.\n",
    "2. For each health region, what was the median number of daily cases per 100,000 in 2021. Print the resulting series. (**Hint:** Think about how long should this series be.)\n",
    "3. What the maximum number of daily cases per 100,000 across all health regions? Which health region did this maximum occur in? What day was the maximum attained?\n",
    "\n",
    "**Hint:** For the last step, you might need to aggregate twice. You may also want to use the aggregator `.idxmax()` which returns the index of the maximum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa16b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2b -- Step 1\n",
    "min_cases_per_date = cases_bc.min(axis=1)\n",
    "print(\"Minimum number of cases per 100,000 at each date (Top 3 rows):\")\n",
    "print(min_cases_per_date.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2b -- Step 2\n",
    "median_cases_per_region = cases_bc.median(axis=0)\n",
    "print(\"\\nMedian number of daily cases per 100,000 for each health region in 2021:\")\n",
    "print(median_cases_per_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cases_all = round(cases_bc.max().max(),3)\n",
    "max_region = cases_bc.max().idxmax()\n",
    "max_date = cases_bc[max_region].idxmax()\n",
    "\n",
    "print(f\"Maximum number of daily cases across all health regions: {max_cases_all}\")\n",
    "print(f\"Health region with the maximum number of daily cases: {max_region}\")\n",
    "print(f\"Date when the maximum number of daily cases occurred: {max_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6cb53c",
   "metadata": {},
   "source": [
    "## Exercise 2c -- Classifying Variance\n",
    "Averages and medians communicate some notion of the statistical center of data. Similarly, the sample variance of data gives us some sense of how dispersed the data is around that center. A low variance means the data is relatively concentrated whereas a high variance means the data is relatively dispersed. The sample variance of a column of data $x$ can be given by the following equation\n",
    "$$\n",
    "var(x) = \\frac{1}{n-1} \\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)^2\n",
    "$$\n",
    "where $n$ is the nimber of elements in $x$, $\\bar{x}$ is the average of $x$, and $x_i$ is a single element in $x$. Complete the following steps:\n",
    "1.  The method DataFrame and Series method `.var()` will automatically calculate the variance of each column or row in a DataFrame. Use `.var()` to calculate the variance in the daily cases per 100,000 for each health region in 2021. Name this DataFrame `hr_var`.\n",
    "2. Currently,  `hr_var` has a single column indexed by the integer 0. Rename this column so it is called \"s_var\".\n",
    "3. Using a list comprehension, create a new column in `hr_var` called \"classification\" which is equal to\n",
    "    - \"High\" if the variance for a health region is strictly greater than 300,  \n",
    "    - \"Medium\" if the variance for a health region is strictly greater than 150 and less than or equal to 300\n",
    "    - \"Low\" if the variance for a health region is less than or equal to 150. \n",
    "    \n",
    "4. Display the resulting DataFrame by having `hr_var` as your last line in the cell. \n",
    "5. In the second cell, use `cases_bc`, indexing, and `.plot()` to plot the daily cases per 100,000 for the Northern and Island health regions.\n",
    "\n",
    "Finally, in the Markdown cell below **answer the following question**. What are the classifications for the Northern and Island regions. What features of the two lines you plotted reflect these classifications? \n",
    "\n",
    "\n",
    "**Hint:** For step 3, you will want to use a nested if else statements within the list comprehension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244840b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2c -- Steps 1-4\n",
    "hr_var = cases_bc.var().to_frame()\n",
    "hr_var.columns = ['s_var']\n",
    "hr_var['classification'] = ''\n",
    "\n",
    "# Classify the variance using a loop and conditional statements\n",
    "for index, row in hr_var.iterrows():\n",
    "    variance = row['s_var']\n",
    "    if variance > 300:\n",
    "        hr_var.at[index, 'classification'] = 'High'\n",
    "    elif variance > 150:\n",
    "        hr_var.at[index, 'classification'] = 'Medium'\n",
    "    else:\n",
    "        hr_var.at[index, 'classification'] = 'Low'\n",
    "hr_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71740a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2c -- Step 5\n",
    "# Plot daily cases per 100,000 for Northern and Island health regions\n",
    "cases_bc[['Northern', 'Island']].plot(figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d92cc",
   "metadata": {},
   "source": [
    "### Response to Exercise 2c\n",
    "\n",
    "The two classifications are 'High' for Northern and 'Low' for Island. This can be shown by the high variance and great fluctuations for the Northern region and low variance and a smoother line for the Island region. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6e22e",
   "metadata": {},
   "source": [
    "## Exerice 2d -- More Classifying & `.applymap()`\n",
    "Now, we want to determine whether the cases per 100,000 on a given day was \"High\" ($> 10$), \"Low\"($\\leq 10$ and $>0$), or \"None\" ($=0$) for each region-day. To do this, complete the following steps:\n",
    "1. Define a function called `classify_cases` that takes a **single number** and returns a \"High\", \"Low\" or \"None\" according to the criteria aboce\n",
    "2. `.applymap()` takes a function of a single value and applies that function to each cell in a DataFrame  individuall. Using `classify_cases` and `.applymap`, create a DataFrame that has a classification for each region-day. Call this DataFrame `cases_bins`. \n",
    "3. Print the top 5 rows of that DataFratme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca95753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2d code\n",
    "def classify_cases(number):\n",
    "    if number > 10:\n",
    "        return 'High'\n",
    "    elif 0 < number <= 10:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "cases_bins = cases_bc.applymap(classify_cases)\n",
    "cases_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2a264",
   "metadata": {},
   "source": [
    "### Exercise 2e -- Classification Count\n",
    "Next, we want to count how many days of each type (\"High\", \"Low\", and \"None\") each helth region had on 2021. Complete the following steps:\n",
    "1. Using `pd.value_counts` and `.apply()`, create DataFrame called `class_counts` where the row indices are the three classes and the columns are health regions.\n",
    "2. Using the DataFrame method `.barh()`, create a horizontal bar plot where there are five groups of three bars. \n",
    "\n",
    "**Hint:** You may have to use `.T` to get the right bar chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677a256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2e code\n",
    "class_counts = cases_bins.apply(pd.value_counts) #Counts occurrences of \"High,\" \"Low,\" and \"None\" for each column (health region)\n",
    "#print(class_counts)\n",
    "\n",
    "# Transpose class_counts for better plotting\n",
    "class_counts = class_counts.T\n",
    "\n",
    "# Plot horizontal bar plot\n",
    "class_counts.plot(kind='barh', figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4be232",
   "metadata": {},
   "source": [
    "### Exercise 2f -- Choose Your Health Region\n",
    "Choose one of the five health regions. Complete the following steps to find the average number of cases per 100,000 when case loads are \"High\" and when case loads are \"Low\".\n",
    "1. Using `pd.concat()` `cases_bc`, and `cases_bin`, create a DataFrame with two columns called `my_health_region`. The first column should be titled \"cases\" and include the number of cases per 100,000 in your chosen health region for each day. The second column should be titled \"class\" and include the classification for that health region in each day.\n",
    "2. Using `.groupby()` and an aggregator, find the average number of cases per 100,000 when case loads are \"High\" and when case loads are \"Low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b17004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2f code\n",
    "health_region = 'Fraser'\n",
    "\n",
    "print(cases_bc)\n",
    "print(cases_bins)\n",
    "\n",
    "my_health_region = pd.concat([\n",
    "    cases_bc[[health_region]].rename(columns={health_region: 'cases'}),\n",
    "    cases_bins[[health_region]].rename(columns={health_region: 'class'})\n",
    "], axis=1)\n",
    "\n",
    "print(my_health_region)\n",
    "\n",
    "filtered = my_health_region[my_health_region['class'].isin(['High', 'Low'])]\n",
    "\n",
    "average_cases = filtered.groupby('class').mean()\n",
    "\n",
    "print(average_cases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d55e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
